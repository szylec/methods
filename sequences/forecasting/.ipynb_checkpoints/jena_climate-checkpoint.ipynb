{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe exact formulation of the problem:\\nGiven data going as far back as lookback timesteps (a timestep is 10 minutes)\\nand sampled every steps timesteps, can you predict the temperature in delay timesteps?\\nYou’ll use the following parameter values:\\n- lookback = 720 — Observations will go back 5 days.\\n- steps = 6 — Observations will be sampled at one data point per hour.\\n- delay = 144 — Targets will be 24 hours in the future.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The exact formulation of the problem:\n",
    "Given data going as far back as lookback timesteps (a timestep is 10 minutes)\n",
    "and sampled every steps timesteps, can you predict the temperature in delay timesteps?\n",
    "You’ll use the following parameter values:\n",
    "- lookback = 720 — Observations will go back 5 days.\n",
    "- steps = 6 — Observations will be sampled at one data point per hour.\n",
    "- delay = 144 — Targets will be 24 hours in the future.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slechwar/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/slechwar/dev/methods/sequences/forecasting'\n",
    "TRAINING_SAMPLES = 200000\n",
    "\n",
    "fname = os.path.join(DATA_DIR, 'jena_climate_2009_2016.csv')\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 s, sys: 66.4 ms, total: 2.69 s\n",
      "Wall time: 2.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def preprocessing(lines, training_samples):\n",
    "    # Change all values to floats.\n",
    "    # Remove 'Date Time' column from further processing.\n",
    "    # Standardize the data.\n",
    "    result = np.zeros((len(lines), len(header) - 1))\n",
    "    for i, line in enumerate(lines):\n",
    "        values = [float(x) for x in line.split(',')[1:]]\n",
    "        result[i, :] = values\n",
    "\n",
    "    mean = result[:training_samples].mean(axis=0)\n",
    "    result -= mean\n",
    "    std = result[:training_samples].std(axis=0)\n",
    "    result /= std\n",
    "\n",
    "    return result, mean, std\n",
    "\n",
    "float_data, mean, std = preprocessing(lines, TRAINING_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- data: The original array of floating-point data.\n",
    "- lookback: How many timesteps back the input data should go.\n",
    "- delay: How many timesteps in the future the target should be.\n",
    "- min_index and max_index: Indices in the data array that delimit which timesteps\n",
    "to draw from. This is useful for keeping a segment of the data for validation\n",
    "and another for testing.\n",
    "- shuffle: Whether to shuffle the samples or draw them in chronological order.\n",
    "- batch_size: The number of samples per batch.\n",
    "- step: The period, in timesteps, at which you sample data. You’ll set it to 6 in\n",
    "order to draw one data point every hour.\n",
    "'''\n",
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "        # Axis:\n",
    "        # 0: Number of samples in the batch.\n",
    "        # 1: Time axis (timestamp). Drawn data point (one hour interval).\n",
    "        # 2: Features axis.\n",
    "        samples = np.zeros((len(rows),\n",
    "                            lookback // step,\n",
    "                            data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1]\n",
    "        yield samples, targets\n",
    "    \n",
    "lookback = 1440\n",
    "step = 6\n",
    "delay = 144\n",
    "batch_size = 128\n",
    "\n",
    "train_gen = generator(\n",
    "    float_data,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=0,\n",
    "    max_index=200000,\n",
    "    shuffle=True,\n",
    "    step=step,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_gen = generator(\n",
    "    float_data,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=200001,\n",
    "    max_index=300000,\n",
    "    step=step,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_gen = generator(\n",
    "    float_data,\n",
    "    lookback=lookback,\n",
    "    delay=delay,\n",
    "    min_index=300001,\n",
    "    max_index=None,\n",
    "    step=step,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "train_steps = (200000 - lookback)\n",
    "val_steps = (300000 - 200001 - lookback)\n",
    "test_steps = (len(float_data) - 300001 - lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.2848166608827257\n",
      "Mean MAE (degrees Celsius): 2.521339229060914\n",
      "CPU times: user 5.95 s, sys: 46.4 ms, total: 6 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Non-ML baseline to beat.\n",
    "# Temperature in next 24h will be the same as temperature in current time.\n",
    "# Lets calculate mean absolut error to check its performance.\n",
    "# To speed things up, take onlt 1/100 of validation dataset.\n",
    "def evaluate_naive_method(std):\n",
    "    batch_maes = []\n",
    "    for _ in range(val_steps // 100):\n",
    "        samples, targets = next(val_gen)\n",
    "        # Take all samples (axis 0),\n",
    "        # from last period/timestamp (axis 1),\n",
    "        # and feature \"T (degC)\" (axis 2)\n",
    "        preds = samples[:, -1, 1]\n",
    "        mae = np.mean(np.abs(preds - targets))\n",
    "        batch_maes.append(mae)\n",
    "    mean_batch_maes = np.mean(batch_maes)\n",
    "    print('Mean MAE: {}'.format(mean_batch_maes))\n",
    "    # Because the temperature data has been normalized to be\n",
    "    # centered on 0 and have a standard deviation of 1, \n",
    "    # this number isn’t immediately interpretable.\n",
    "    # Need to multiply with standard deviation to get interpretable value.\n",
    "    print('Mean MAE (degrees Celsius): {}'.format(mean_batch_maes * std[1]))\n",
    "    \n",
    "evaluate_naive_method(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 3360)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                107552    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 107,585\n",
      "Trainable params: 107,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1551/1551 [==============================] - 22s 14ms/step - loss: 0.6609 - val_loss: 0.3212\n",
      "Epoch 2/20\n",
      "1551/1551 [==============================] - 23s 15ms/step - loss: 0.2500 - val_loss: 0.3275\n",
      "Epoch 3/20\n",
      "1551/1551 [==============================] - 21s 14ms/step - loss: 0.2289 - val_loss: 0.3205\n",
      "Epoch 4/20\n",
      " 167/1551 [==>...........................] - ETA: 14s - loss: 0.2223"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Basic ML approach.\n",
    "# Regression model.\n",
    "\n",
    "def regression_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Flatten expect shape without batches.\n",
    "    # Here we pass (number of timeseries samples, number of featuers).\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    # Last layer without activation (typical for regression problems).\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(),\n",
    "        loss='mae')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = regression_model()\n",
    "# Bug probably...\n",
    "# In order to run this, set:\n",
    "# - steps_per_epoch=train_steps // batch_size,\n",
    "# - validation_steps=val_steps // batch_size,\n",
    "# - workers=1,\n",
    "# - use_multiprocessing=False\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps // batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps // batch_size,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
